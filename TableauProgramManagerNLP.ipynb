{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Packages\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "import gensim\n",
    "from gensim import summarization\n",
    "from gensim.summarization import summarizer\n",
    "from gensim.summarization.summarizer import summarize\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import scatter\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from numpy import add\n",
    "from gensim import models\n",
    "from numpy import reshape\n",
    "import codecs\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import csv\n",
    "warnings = False\n",
    "from operator import add\n",
    "import gzip\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import Cython\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from gensim.models import word2vec\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Downloads/GoogleNews-vectors-negative300.bin.gz', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = pd.read_csv(\"C:\\\\Users\\\\gbusch\\\\Desktop\\\\25SampleNLP.csv\", 'utf-8',engine='python',error_bad_lines=False, dtype=str); \n",
    "documents = pd.DataFrame(documents)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents['Duty'] = documents['Duty'].str.replace('\\d+', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\\\xa0', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\\"', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\t', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\.', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\~', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\(', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\)', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\-', ' ')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\'', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\–', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\’', '') \n",
    "documents['Duty'] = documents['Duty'].str.replace('\\“', '')\n",
    "documents['Duty'] = documents['Duty'].str.replace('\\”', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents['Duty'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doclist = documents['Duty'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doclist_without_stopwords = []\n",
    "for sentence in doclist:\n",
    "    new_sentence = []\n",
    "    for word in sentence.split():\n",
    "        if word not in stop_words:\n",
    "            new_sentence.append(word)\n",
    "    doclist_without_stopwords.append(' '.join(new_sentence))\n",
    "doclist_without_stopwords\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = model.get_vector('SQL')\n",
    "model.add('VizQL',c1)\n",
    "c2 = model.get_vector('Company')\n",
    "model.add('Inovalon',c2)\n",
    "c3 = model.get_vector('SQL')\n",
    "model.add('VizSQL',c3)\n",
    "c4 = model.get_vector('database')\n",
    "model.add('ORDBMS',c4)\n",
    "c5 = model.get_vector('SQL')\n",
    "model.add('TABCMD',c5)\n",
    "model.add('TABADMIN',c5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "errorlist = []\n",
    "vectors = []\n",
    "for x in doclist_without_stopwords:\n",
    "    sentvecs = np.zeros(300)\n",
    "    for y in x.split():\n",
    "        if pd.isnull(y) == False and y.isnumeric() == False:\n",
    "            try:\n",
    "                sentvecs = np.add(sentvecs,model.get_vector(y))\n",
    "            except KeyError:\n",
    "                i+=1\n",
    "                errorlist.append(y)\n",
    "                continue\n",
    "            except IndexError:\n",
    "                continue\n",
    "    vectors.append(sentvecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumofvectors = []\n",
    "for n in vectors:\n",
    "    sumofvectors.append(np.add(n[:],n[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumofvectors = pd.DataFrame(sumofvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "vecfit = pd.DataFrame(pca.fit_transform(sumofvectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final1 = pd.DataFrame(vecfit)\n",
    "kmeans_model = KMeans(n_clusters=15, init='k-means++',max_iter=100)\n",
    "X = kmeans_model.fit(vecfit)\n",
    "labels = kmeans_model.labels_.tolist()\n",
    "labels = pd.DataFrame(labels)\n",
    "labels\n",
    "final = vecfit.merge(labels, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,30)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(vecfit)\n",
    "    kmeanModel.fit(vecfit)\n",
    "    distortions.append(sum(np.min(cdist(vecfit, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / vecfit.shape[0])\n",
    "dist = cdist(vecfit, kmeanModel.cluster_centers_, 'euclidean')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "figure(num=None, figsize=(7, 7), dpi=100\n",
    "    , facecolor='w', edgecolor='k')\n",
    "\n",
    "centers = kmeans_model.cluster_centers_\n",
    "x = final['0_x']\n",
    "y = final[1]\n",
    "c = final['0_y']\n",
    "plt.scatter(x,y,c=c,alpha=1)\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=1, alpha=1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,30)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(vecfit)\n",
    "    kmeanModel.fit(vecfit)\n",
    "    distortions.append(sum(np.min(cdist(vecfit, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / vecfit.shape[0])\n",
    "dist = cdist(vecfit, kmeanModel.cluster_centers_, 'euclidean')\n",
    "dist.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "centersdf = pd.DataFrame(centers)\n",
    "centersdf1 = centersdf.reset_index(drop=False)\n",
    "centersdf1\n",
    "dataout = final.merge(centersdf1, left_on='0_y', right_on='index', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataout['Distance'] = np.sqrt(abs(np.power((dataout['0_x']-dataout[0]),2)-np.power((dataout['1_x']-dataout['1_y']),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "for dataout in dataout['0_y']:\n",
    "    centroids.append(min(dataout['Distance']))\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = []\n",
    "for dataout in dataout['0_y']:\n",
    "    centroids.append(min(dataout['Distance']))\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataoutcsv = dataout.merge(pd.DataFrame(documents['Duty']), left_index=True, right_index=True, how='inner')\n"
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataoutcsv.to_csv(\"C:\\\\Users\\\\gbusch\\\\Desktop\\\\ProgramManagerNLP.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
